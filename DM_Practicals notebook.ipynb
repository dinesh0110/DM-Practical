{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5snDGTOH8D8qok7Xo+5YI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinesh0110/DM-Practical/blob/main/DM_Practicals%20notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        ">### Practical 1 - MDP###\n",
        "\n"
      ],
      "metadata": {
        "id": "G2gpeqp5i2OV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Practical 1\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "### MDP Algorithms ###\n",
        "\n",
        "def value_iteration(P, R, gamma=0.9, epsilon=1e-6):\n",
        "    n_states, n_actions = R.shape[1], R.shape[0]\n",
        "    V = np.zeros(n_states)\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in range(n_states):\n",
        "            v = V[s]\n",
        "            V[s] = max(sum(P[a, s, s1] * (R[a, s] + gamma * V[s1]) for s1 in range(n_states)) for a in range(n_actions))\n",
        "            delta = max(delta, abs(v - V[s]))\n",
        "        if delta < epsilon:\n",
        "            break\n",
        "    policy = np.argmax([[sum(P[a, s, s1] * (R[a, s] + gamma * V[s1]) for s1 in range(n_states)) for a in range(n_actions)] for s in range(n_states)], axis=1)\n",
        "    return policy, V\n",
        "\n",
        "def policy_iteration(P, R, gamma=0.9, epsilon=1e-6):\n",
        "    n_states, n_actions = R.shape[1], R.shape[0]\n",
        "    policy = np.zeros(n_states, dtype=int)\n",
        "    V = np.zeros(n_states)\n",
        "    while True:\n",
        "        while True:\n",
        "            delta = 0\n",
        "            for s in range(n_states):\n",
        "                v = V[s]\n",
        "                V[s] = sum(P[policy[s], s, s1] * (R[policy[s], s] + gamma * V[s1]) for s1 in range(n_states))\n",
        "                delta = max(delta, abs(v - V[s]))\n",
        "            if delta < epsilon:\n",
        "                break\n",
        "        policy_stable = True\n",
        "        for s in range(n_states):\n",
        "            old_action = policy[s]\n",
        "            policy[s] = np.argmax([sum(P[a, s, s1] * (R[a, s] + gamma * V[s1]) for s1 in range(n_states)) for a in range(n_actions)])\n",
        "            if old_action != policy[s]:\n",
        "                policy_stable = False\n",
        "        if policy_stable:\n",
        "            break\n",
        "    return policy, V\n",
        "\n",
        "def q_learning(P, R, gamma=0.9, alpha=0.1, epsilon=0.1, episodes=1000):\n",
        "    n_states, n_actions = R.shape[1], R.shape[0]\n",
        "    Q = np.zeros((n_states, n_actions))\n",
        "    for _ in range(episodes):\n",
        "        state = random.choice(range(n_states))\n",
        "        while True:\n",
        "            if random.uniform(0, 1) < epsilon:\n",
        "                action = random.choice(range(n_actions))\n",
        "            else:\n",
        "                action = np.argmax(Q[state])\n",
        "            next_state = np.argmax(P[action, state])\n",
        "            reward = R[action, state]\n",
        "            best_next_action = np.argmax(Q[next_state])\n",
        "            td_target = reward + gamma * Q[next_state, best_next_action]\n",
        "            td_error = td_target - Q[state, action]\n",
        "            Q[state, action] += alpha * td_error\n",
        "            if state == next_state:\n",
        "                break\n",
        "            state = next_state\n",
        "    policy = np.argmax(Q, axis=1)\n",
        "    return policy, Q\n",
        "\n",
        "### Utility Functions ###\n",
        "\n",
        "def validate_transition_matrix(P):\n",
        "    assert np.allclose(P.sum(axis=2), 1), \"Transition probabilities must sum to 1.\"\n",
        "\n",
        "def validate_reward_matrix(R, P):\n",
        "    assert R.shape == P.shape[:2], \"Reward matrix dimensions must match the transition matrix.\"\n",
        "\n",
        "def generate_random_mdp(n_states, n_actions):\n",
        "    P = np.zeros((n_actions, n_states, n_states))\n",
        "    for a in range(n_actions):\n",
        "        for s in range(n_states):\n",
        "            P[a, s, :] = np.random.dirichlet(np.ones(n_states))\n",
        "    R = np.random.rand(n_actions, n_states)\n",
        "    return P, R\n",
        "\n",
        "### Example Usage ###\n",
        "\n",
        "# Generate a random MDP\n",
        "n_states = 3\n",
        "n_actions = 2\n",
        "P, R = generate_random_mdp(n_states, n_actions)\n",
        "\n",
        "# Validate the MDP\n",
        "validate_transition_matrix(P)\n",
        "validate_reward_matrix(R, P)\n",
        "\n",
        "# Solve the MDP using Value Iteration\n",
        "policy_vi, V_vi = value_iteration(P, R)\n",
        "print(\"Optimal Policy (Value Iteration):\", policy_vi)\n",
        "print(\"Value Function (Value Iteration):\", V_vi)\n",
        "\n",
        "# Solve the MDP using Policy Iteration\n",
        "policy_pi, V_pi = policy_iteration(P, R)\n",
        "print(\"Optimal Policy (Policy Iteration):\", policy_pi)\n",
        "print(\"Value Function (Policy Iteration):\", V_pi)\n",
        "\n",
        "# Solve the MDP using Q-Learning\n",
        "policy_ql, Q_ql = q_learning(P, R)\n",
        "print(\"Optimal Policy (Q-Learning):\", policy_ql)\n",
        "print(\"Q-Table (Q-Learning):\", Q_ql)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YchzvfwojH6n",
        "outputId": "ea76d7da-c49a-4bd9-99f2-5900ccc708b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy (Value Iteration): [1 0 0]\n",
            "Value Function (Value Iteration): [4.62721478 4.88860481 5.0434772 ]\n",
            "Optimal Policy (Policy Iteration): [1 0 0]\n",
            "Value Function (Policy Iteration): [4.62721535 4.88860532 5.04347768]\n",
            "Optimal Policy (Q-Learning): [0 0 0]\n",
            "Q-Table (Q-Learning): [[4.23076394 4.15585996]\n",
            " [4.45664846 4.2141524 ]\n",
            " [4.56083248 4.06667042]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 2 MONTE_CARLO ###"
      ],
      "metadata": {
        "id": "RZqYoG1Xqt7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pract 2\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def generate_episode(P, R, policy, n_states, max_steps=100):\n",
        "    episode = []\n",
        "    state = random.choice(range(n_states))\n",
        "    for _ in range(max_steps):\n",
        "        action = policy[state]\n",
        "        next_state = np.random.choice(range(n_states), p=P[action, state])\n",
        "        reward = R[action, state]\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "        if state == next_state:  # Assuming episode ends when reaching a terminal state\n",
        "            break\n",
        "    return episode\n",
        "\n",
        "def monte_carlo_control(P, R, n_states, n_actions, gamma=0.9, epsilon=0.1, episodes=1000):\n",
        "    Q = np.zeros((n_states, n_actions))\n",
        "    returns = { (s, a): [] for s in range(n_states) for a in range(n_actions) }\n",
        "    policy = np.zeros(n_states, dtype=int)\n",
        "\n",
        "    for _ in range(episodes):\n",
        "        episode = generate_episode(P, R, policy, n_states)\n",
        "        G = 0\n",
        "        for t in reversed(range(len(episode))):\n",
        "            state, action, reward = episode[t]\n",
        "            G = gamma * G + reward\n",
        "            if not any((state == x[0] and action == x[1]) for x in episode[:t]):\n",
        "                returns[(state, action)].append(G)\n",
        "                Q[state, action] = np.mean(returns[(state, action)])\n",
        "                policy[state] = np.argmax(Q[state])\n",
        "\n",
        "    return policy, Q\n",
        "\n",
        "### Utility Functions ###\n",
        "\n",
        "def validate_transition_matrix(P):\n",
        "    assert np.allclose(P.sum(axis=2), 1), \"Transition probabilities must sum to 1.\"\n",
        "\n",
        "def validate_reward_matrix(R, P):\n",
        "    assert R.shape == P.shape[:2], \"Reward matrix dimensions must match the transition matrix.\"\n",
        "\n",
        "def generate_random_mdp(n_states, n_actions):\n",
        "    P = np.zeros((n_actions, n_states, n_states))\n",
        "    for a in range(n_actions):\n",
        "        for s in range(n_states):\n",
        "            P[a, s, :] = np.random.dirichlet(np.ones(n_states))\n",
        "    R = np.random.rand(n_actions, n_states)\n",
        "    return P, R\n",
        "\n",
        "### Example Usage ###\n",
        "\n",
        "# Generate a random MDP\n",
        "n_states = 3\n",
        "n_actions = 2\n",
        "P, R = generate_random_mdp(n_states, n_actions)\n",
        "\n",
        "# Validate the MDP\n",
        "validate_transition_matrix(P)\n",
        "validate_reward_matrix(R, P)\n",
        "\n",
        "# Solve the MDP using Monte Carlo Control\n",
        "policy_mc, Q_mc = monte_carlo_control(P, R, n_states, n_actions)\n",
        "print(\"Optimal Policy (Monte Carlo Control):\", policy_mc)\n",
        "print(\"Q-Table (Monte Carlo Control):\", Q_mc)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw2IG2IuqwpE",
        "outputId": "f153087d-eaa4-4b58-ad0f-bda32141d535"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy (Monte Carlo Control): [0 0 0]\n",
            "Q-Table (Monte Carlo Control): [[0.78276677 0.        ]\n",
            " [0.08028752 0.        ]\n",
            " [0.93035376 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 3 Q-Learning_algorithm ###"
      ],
      "metadata": {
        "id": "__v_Dm3BrUSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "# Create the environment\n",
        "env = gym.make('Taxi-v3')\n",
        "\n",
        "# Initialize Q-table with zeros\n",
        "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "# Set hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.6  # Discount factor\n",
        "epsilon = 0.1  # Exploration rate\n",
        "\n",
        "# Number of episodes\n",
        "episodes = 1000\n",
        "\n",
        "# Q-Learning algorithm\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        # Epsilon-greedy policy\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Exploration\n",
        "        else:\n",
        "            action = np.argmax(Q[state])  # Exploitation\n",
        "\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        # Q-value update\n",
        "        old_q_value = Q[state, action]\n",
        "        next_max = np.max(Q[next_state])\n",
        "        new_q_value = (1 - alpha) * old_q_value + alpha * (reward + gamma * next_max)\n",
        "        Q[state, action] = new_q_value\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "# Print the learned Q-table\n",
        "print(\"Learned Q-table:\")\n",
        "print(Q)\n",
        "\n",
        "# Evaluate the learned policy\n",
        "total_rewards = 0\n",
        "episodes = 100\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = np.argmax(Q[state])\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        total_rewards += reward\n",
        "\n",
        "# Average reward over episodes\n",
        "average_reward = total_rewards / episodes\n",
        "print(\"Average Reward:\", average_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LfFE86arYkL",
        "outputId": "f0807e16-aea4-4ba4-c872-a14c9fe506a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Q-table:\n",
            "[[ 0.          0.          0.          0.          0.          0.        ]\n",
            " [-2.29281068 -2.28269962 -2.2828092  -2.28330468 -2.28369154 -2.8458504 ]\n",
            " [-1.79099003 -1.77733091 -1.78028688 -1.74787596 -0.80157302 -4.97324425]\n",
            " ...\n",
            " [-1.19899269 -1.02011789 -1.19560465 -1.15685098 -1.95401479 -4.30092563]\n",
            " [-1.99116032 -2.001472   -1.99062573 -1.99528348 -2.84803942 -3.54754891]\n",
            " [-0.196      -0.196      -0.1         4.78963035 -1.         -1.        ]]\n",
            "Average Reward: -170.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 4 AVI_API ###"
      ],
      "metadata": {
        "id": "C-MWrusdsRlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# AVI implementation\n",
        "class ApproximateValueIteration:\n",
        "    def __init__(self, state_dim, action_dim, feature_dim, gamma=0.9, epsilon=1e-6, max_iterations=1000):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.feature_dim = feature_dim\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.max_iterations = max_iterations\n",
        "        self.weights = np.zeros((action_dim, feature_dim))\n",
        "\n",
        "    def compute_q_values(self, state):\n",
        "        q_values = np.dot(self.weights, state)\n",
        "        return q_values\n",
        "\n",
        "    def train(self, feature_matrix, reward_matrix):\n",
        "        for _ in range(self.max_iterations):\n",
        "            prev_weights = np.copy(self.weights)\n",
        "            for state_idx in range(self.state_dim):\n",
        "                state = feature_matrix[state_idx]\n",
        "                q_values = self.compute_q_values(state)\n",
        "                best_action_value = np.max(q_values)\n",
        "                for action_idx in range(self.action_dim):\n",
        "                    reward = reward_matrix[action_idx, state_idx]\n",
        "                    bellman_residual = reward + self.gamma * best_action_value - q_values[action_idx]\n",
        "                    self.weights[action_idx] += np.dot(state, bellman_residual)\n",
        "            if np.linalg.norm(prev_weights - self.weights) < self.epsilon:\n",
        "                break\n",
        "\n",
        "    def get_policy(self, feature_matrix):\n",
        "        policy = np.zeros(self.state_dim, dtype=int)\n",
        "        for state_idx in range(self.state_dim):\n",
        "            state = feature_matrix[state_idx]\n",
        "            q_values = self.compute_q_values(state)\n",
        "            policy[state_idx] = np.argmax(q_values)\n",
        "        return policy\n",
        "\n",
        "# API implementation\n",
        "class ApproximatePolicyIteration:\n",
        "    def __init__(self, state_dim, action_dim, feature_dim, gamma=0.9, epsilon=1e-6, max_iterations=1000):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.feature_dim = feature_dim\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.max_iterations = max_iterations\n",
        "        self.weights = np.zeros((action_dim, feature_dim))\n",
        "\n",
        "    def compute_q_values(self, state):\n",
        "        q_values = np.dot(self.weights, state)\n",
        "        return q_values\n",
        "\n",
        "    def compute_value_function(self, feature_matrix):\n",
        "        value_function = np.zeros(self.state_dim)\n",
        "        for state_idx in range(self.state_dim):\n",
        "            state = feature_matrix[state_idx]\n",
        "            q_values = self.compute_q_values(state)\n",
        "            value_function[state_idx] = np.max(q_values)\n",
        "        return value_function\n",
        "\n",
        "    def train(self, feature_matrix, reward_matrix):\n",
        "        for _ in range(self.max_iterations):\n",
        "            prev_weights = np.copy(self.weights)\n",
        "            for _ in range(self.max_iterations):\n",
        "                prev_value_function = self.compute_value_function(feature_matrix)\n",
        "                for state_idx in range(self.state_dim):\n",
        "                    state = feature_matrix[state_idx]\n",
        "                    q_values = self.compute_q_values(state)\n",
        "                    policy = np.argmax(q_values)\n",
        "                    reward = reward_matrix[policy, state_idx]\n",
        "                    bellman_residual = reward + self.gamma * prev_value_function[state_idx] - q_values[policy]\n",
        "                    self.weights[policy] += np.dot(state, bellman_residual)\n",
        "                value_function = self.compute_value_function(feature_matrix)\n",
        "                if np.linalg.norm(prev_value_function - value_function) < self.epsilon:\n",
        "                    break\n",
        "            if np.linalg.norm(prev_weights - self.weights) < self.epsilon:\n",
        "                break\n",
        "\n",
        "    def get_policy(self, feature_matrix):\n",
        "        policy = np.zeros(self.state_dim, dtype=int)\n",
        "        for state_idx in range(self.state_dim):\n",
        "            state = feature_matrix[state_idx]\n",
        "            q_values = self.compute_q_values(state)\n",
        "            policy[state_idx] = np.argmax(q_values)\n",
        "        return policy\n",
        "\n",
        "# Example Usage and Output:\n",
        "\n",
        "# Define example data\n",
        "state_dim = 5\n",
        "action_dim = 2\n",
        "feature_dim = 3\n",
        "gamma = 0.9\n",
        "epsilon = 1e-6\n",
        "max_iterations = 1000\n",
        "\n",
        "feature_matrix = np.random.rand(state_dim, feature_dim)\n",
        "reward_matrix = np.random.rand(action_dim, state_dim)\n",
        "\n",
        "# Instantiate and train AVI\n",
        "avi = ApproximateValueIteration(state_dim, action_dim, feature_dim, gamma, epsilon, max_iterations)\n",
        "avi.train(feature_matrix, reward_matrix)\n",
        "\n",
        "# Obtain AVI policy\n",
        "avi_policy = avi.get_policy(feature_matrix)\n",
        "print(\"Approximate Value Iteration (AVI) Policy:\")\n",
        "print(avi_policy)\n",
        "\n",
        "# Instantiate and train API\n",
        "api = ApproximatePolicyIteration(state_dim, action_dim, feature_dim, gamma, epsilon, max_iterations)\n",
        "api.train(feature_matrix, reward_matrix)\n",
        "\n",
        "# Obtain API policy\n",
        "api_policy = api.get_policy(feature_matrix)\n",
        "print(\"Approximate Policy Iteration (API) Policy:\")\n",
        "print(api_policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuZWDqV7sZ3B",
        "outputId": "6da9bb78-1150-4b48-be02-462fff3de615"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate Value Iteration (AVI) Policy:\n",
            "[0 0 0 0 0]\n",
            "Approximate Policy Iteration (API) Policy:\n",
            "[0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 5 Actor-Critic-Algorithm ###"
      ],
      "metadata": {
        "id": "e7o2i0IbsgM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gym\n",
        "\n",
        "# Actor Model\n",
        "class Actor(tf.keras.Model):\n",
        "    def __init__(self, state_dim, action_dim, action_bound):\n",
        "        super(Actor, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.dense3 = tf.keras.layers.Dense(action_dim, activation='tanh')\n",
        "        self.action_bound = action_bound\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Reshape the input tensor to have a shape of (batch_size, input_dim)\n",
        "        x = tf.expand_dims(inputs, axis=0)  # Add a batch dimension\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dense3(x)\n",
        "        return tf.squeeze(x, axis=0)  # Remove the added batch dimension\n",
        "\n",
        "\n",
        "# Critic Model\n",
        "class Critic(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.dense3 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Reshape the input tensor to have a shape of (batch_size, input_dim)\n",
        "        x = tf.expand_dims(inputs, axis=0)  # Add a batch dimension\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dense3(x)\n",
        "        return tf.squeeze(x, axis=0)  # Remove the added batch dimension\n",
        "\n",
        "\n",
        "# Actor-Critic Agent\n",
        "class ActorCriticAgent:\n",
        "    def __init__(self, state_dim, action_dim, action_bound, gamma=0.99, actor_lr=0.001, critic_lr=0.001):\n",
        "        self.actor = Actor(state_dim, action_dim, action_bound)\n",
        "        self.critic = Critic()\n",
        "        self.actor_optimizer = tf.keras.optimizers.Adam(learning_rate=actor_lr)\n",
        "        self.critic_optimizer = tf.keras.optimizers.Adam(learning_rate=critic_lr)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def get_action(self, state):\n",
        "        return self.actor(tf.convert_to_tensor([state])).numpy()[0]\n",
        "\n",
        "    def train(self, states, actions, rewards, next_states, dones):\n",
        "        # Compute TD targets\n",
        "        next_q_values = self.critic(tf.convert_to_tensor(next_states, dtype=tf.float32))\n",
        "        targets = rewards + (1 - dones) * self.gamma * next_q_values.numpy().flatten()\n",
        "\n",
        "        # Compute advantages\n",
        "        values = self.critic(tf.convert_to_tensor(states, dtype=tf.float32)).numpy().flatten()\n",
        "        advantages = targets - values\n",
        "\n",
        "        # Train actor\n",
        "        with tf.GradientTape() as tape:\n",
        "            actor_actions = self.actor(tf.convert_to_tensor(states, dtype=tf.float32))\n",
        "            actor_loss = -tf.reduce_mean(self.critic(tf.convert_to_tensor(states, dtype=tf.float32)) * actor_actions)\n",
        "        actor_grads = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
        "        self.actor_optimizer.apply_gradients(zip(actor_grads, self.actor.trainable_variables))\n",
        "\n",
        "        # Train critic\n",
        "        with tf.GradientTape() as tape:\n",
        "            critic_values = self.critic(tf.convert_to_tensor(states, dtype=tf.float32))\n",
        "            critic_loss = tf.reduce_mean(tf.square(targets - critic_values))\n",
        "        critic_grads = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
        "        self.critic_optimizer.apply_gradients(zip(critic_grads, self.critic.trainable_variables))\n",
        "\n",
        "# Example Usage\n",
        "env = gym.make('Pendulum-v1')\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0]\n",
        "action_bound = env.action_space.high[0]\n",
        "\n",
        "agent = ActorCriticAgent(state_dim, action_dim, action_bound)\n",
        "\n",
        "episodes = 10\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    episode_reward = 0\n",
        "    while True:\n",
        "        action = agent.get_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        agent.train(state, action, reward, next_state, done)\n",
        "        episode_reward += reward\n",
        "        state = next_state\n",
        "        if done:\n",
        "            print(\"Episode:\", episode + 1, \"Reward:\", episode_reward)\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "796m47xWsoiG",
        "outputId": "28d17db8-95aa-4bdb-9d46-b4a4c692c8c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1 Reward: -1381.7101894163716\n",
            "Episode: 2 Reward: -1287.421598751571\n",
            "Episode: 3 Reward: -1188.5699966689876\n",
            "Episode: 4 Reward: -1534.538269096972\n",
            "Episode: 5 Reward: -1376.8168674094727\n",
            "Episode: 6 Reward: -1738.0727874743118\n",
            "Episode: 7 Reward: -1383.2954255913392\n",
            "Episode: 8 Reward: -701.4406448217962\n",
            "Episode: 9 Reward: -1371.1079353462671\n",
            "Episode: 10 Reward: -1381.8765271289308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 6 RTDP ###"
      ],
      "metadata": {
        "id": "psFrCPK3s078"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class RTDP:\n",
        "    def __init__(self, state_space, action_space, transition_model, reward_model, gamma=0.9, max_iterations=1000):\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.transition_model = transition_model\n",
        "        self.reward_model = reward_model\n",
        "        self.gamma = gamma\n",
        "        self.max_iterations = max_iterations\n",
        "\n",
        "        self.value_function = np.zeros(len(state_space))\n",
        "        self.policy = np.zeros(len(state_space), dtype=int)\n",
        "\n",
        "    def run(self):\n",
        "        for _ in range(self.max_iterations):\n",
        "            for state in self.state_space:\n",
        "                action_values = []\n",
        "                for action in self.action_space:\n",
        "                    next_state = self.transition_model(state, action)\n",
        "                    reward = self.reward_model(state, action, next_state)\n",
        "                    action_value = reward + self.gamma * self.value_function[next_state]\n",
        "                    action_values.append(action_value)\n",
        "                best_action = np.argmax(action_values)\n",
        "                best_value = action_values[best_action]\n",
        "                self.value_function[state] = best_value\n",
        "                self.policy[state] = best_action\n",
        "\n",
        "def transition_model(state, action):\n",
        "    # Simple grid world transition model\n",
        "    if action == 'up':\n",
        "        return state - 3 if state >= 3 else state\n",
        "    elif action == 'down':\n",
        "        return state + 3 if state < 6 else state\n",
        "    elif action == 'left':\n",
        "        return state - 1 if state % 3 != 0 else state\n",
        "    elif action == 'right':\n",
        "        return state + 1 if state % 3 != 2 else state\n",
        "\n",
        "def reward_model(state, action, next_state):\n",
        "    # Simple reward model: -1 for every step\n",
        "    return -1\n",
        "\n",
        "# Define the state and action space\n",
        "state_space = np.arange(9)\n",
        "action_space = ['up', 'down', 'left', 'right']\n",
        "\n",
        "# Create an instance of RTDP\n",
        "rtdp = RTDP(state_space, action_space, transition_model, reward_model)\n",
        "\n",
        "# Run RTDP\n",
        "rtdp.run()\n",
        "\n",
        "# Print the optimal policy\n",
        "print(\"Optimal Policy:\")\n",
        "for i, action in enumerate(rtdp.policy):\n",
        "    print(f\"State {i}: {action_space[action]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7QLn_8Ks6zo",
        "outputId": "7fb150df-ad9c-4eb8-db94-b2a89c402beb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy:\n",
            "State 0: up\n",
            "State 1: up\n",
            "State 2: up\n",
            "State 3: up\n",
            "State 4: up\n",
            "State 5: up\n",
            "State 6: up\n",
            "State 7: up\n",
            "State 8: up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ### Practical 7 SARSA_Algorithm ###"
      ],
      "metadata": {
        "id": "gc7D9dSotX1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import gym\n",
        "\n",
        "class SARSA:\n",
        "    def __init__(self, env, alpha=0.1, gamma=0.99, epsilon=0.1, max_episodes=1000, max_steps=100):\n",
        "        self.env = env\n",
        "        self.alpha = alpha  # learning rate\n",
        "        self.gamma = gamma  # discount factor\n",
        "        self.epsilon = epsilon  # exploration-exploitation tradeoff\n",
        "        self.max_episodes = max_episodes\n",
        "        self.max_steps = max_steps\n",
        "        self.q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.uniform(0, 1) < self.epsilon:\n",
        "            return self.env.action_space.sample()  # Explore action space\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state, :])  # Exploit learned values\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state, next_action):\n",
        "        predict = self.q_table[state, action]\n",
        "        target = reward + self.gamma * self.q_table[next_state, next_action]\n",
        "        self.q_table[state, action] += self.alpha * (target - predict)\n",
        "\n",
        "    def train(self):\n",
        "        rewards = []\n",
        "        for episode in range(self.max_episodes):\n",
        "            state = self.env.reset()\n",
        "            total_reward = 0\n",
        "            action = self.choose_action(state)\n",
        "            for step in range(self.max_steps):\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                next_action = self.choose_action(next_state)\n",
        "                self.update_q_table(state, action, reward, next_state, next_action)\n",
        "                total_reward += reward\n",
        "                state = next_state\n",
        "                action = next_action\n",
        "                if done:\n",
        "                    break\n",
        "            rewards.append(total_reward)\n",
        "        return rewards\n",
        "\n",
        "# Create a grid world environment\n",
        "env = gym.make(\"FrozenLake-v1\")\n",
        "\n",
        "# Create an instance of SARSA\n",
        "sarsa_agent = SARSA(env)\n",
        "\n",
        "# Train SARSA\n",
        "rewards = sarsa_agent.train()\n",
        "\n",
        "# Print average rewards\n",
        "print(\"Average Rewards:\", np.mean(rewards))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqS_p2BRthOc",
        "outputId": "6eea9794-b063-4b03-cf4b-be2d5c7b20ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Rewards: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 8 Rollout_Algorithm ###\n"
      ],
      "metadata": {
        "id": "cPcnpoRPtplT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class RolloutAgent:\n",
        "    def __init__(self, env, max_rollouts=100):\n",
        "        self.env = env\n",
        "        self.max_rollouts = max_rollouts\n",
        "\n",
        "    def rollout(self, state, action):\n",
        "        total_reward = 0\n",
        "        for _ in range(self.max_rollouts):\n",
        "            rollout_env = self.env.clone()  # Create a copy of the environment for the rollout\n",
        "            rollout_env.set_state(state)\n",
        "            rollout_env.step(action)\n",
        "            rollout_reward = 0\n",
        "            done = False\n",
        "            while not done:\n",
        "                rollout_action = random.choice(rollout_env.get_possible_actions())\n",
        "                _, reward, done, _ = rollout_env.step(rollout_action)\n",
        "                rollout_reward += reward\n",
        "            total_reward += rollout_reward\n",
        "        return total_reward / self.max_rollouts\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        possible_actions = self.env.get_possible_actions()\n",
        "        action_values = [self.rollout(state, action) for action in possible_actions]\n",
        "        best_action = possible_actions[np.argmax(action_values)]\n",
        "        return best_action\n",
        "\n",
        "# Example Usage\n",
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.state = (0, 0)\n",
        "        self.grid_size = 5\n",
        "\n",
        "    def set_state(self, state):\n",
        "        self.state = state\n",
        "\n",
        "    def get_possible_actions(self):\n",
        "        return ['up', 'down', 'left', 'right']\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 'up' and self.state[0] > 0:\n",
        "            self.state = (self.state[0] - 1, self.state[1])\n",
        "        elif action == 'down' and self.state[0] < self.grid_size - 1:\n",
        "            self.state = (self.state[0] + 1, self.state[1])\n",
        "        elif action == 'left' and self.state[1] > 0:\n",
        "            self.state = (self.state[0], self.state[1] - 1)\n",
        "        elif action == 'right' and self.state[1] < self.grid_size - 1:\n",
        "            self.state = (self.state[0], self.state[1] + 1)\n",
        "        reward = -1 if self.state != (self.grid_size - 1, self.grid_size - 1) else 0  # -1 for each step, 0 at goal\n",
        "        done = self.state == (self.grid_size - 1, self.grid_size - 1)\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "    def clone(self):\n",
        "        return GridWorld()\n",
        "\n",
        "env = GridWorld()\n",
        "rollout_agent = RolloutAgent(env)\n",
        "\n",
        "# Perform a rollout from the initial state\n",
        "initial_state = (0, 0)\n",
        "best_action = rollout_agent.choose_action(initial_state)\n",
        "print(\"Best action to take from state\", initial_state, \":\", best_action)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R06KxqRjtwiW",
        "outputId": "e1db776e-a733-4ef0-c9fb-6c9797d18961"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best action to take from state (0, 0) : down\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 9a SuperMarioBro ###\n"
      ],
      "metadata": {
        "id": "Q-rI9wBkt122"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install 'stable-baselines3[extra]'\n",
        "!pip install wandb\n",
        "!pip install box2d-py\n",
        "!pip install gym_super_mario_bros==7.3.0 nes_py\n",
        "!pip install opencv-python\n",
        "\n",
        "import gym\n",
        "import os\n",
        "import wandb\n",
        "import gym_super_mario_bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from gym.wrappers import GrayScaleObservation\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv,VecVideoRecorder, VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "import os\n",
        "\n",
        "# Initialize Gym environment\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "env = GrayScaleObservation(env, keep_dim=True)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "env = VecFrameStack(env, 4, channels_order='last')\n",
        "\n",
        "# Define environment name and configuration\n",
        "env_name = \"SuperMarioBros-v0\"\n",
        "config = {\n",
        "    \"policy_type\": \"CnnPolicy\",\n",
        "    \"total_timesteps\": 25000,\n",
        "    \"env_name\": env_name,\n",
        "}\n",
        "\n",
        "# Initialize WandB run\n",
        "run = wandb.init(\n",
        "    project=\"intro_to_gym\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,\n",
        "    monitor_gym=True,\n",
        "    save_code=True,\n",
        ")\n",
        "\n",
        "# Setup video recording\n",
        "env_with_recording = VecVideoRecorder(\n",
        "    env, f\"videos/{run.id}\",\n",
        "    record_video_trigger=lambda x: x % 2000 == 0,\n",
        "    video_length=200\n",
        ")\n",
        "\n",
        "# Create and train the model\n",
        "model = PPO(config[\"policy_type\"], env_with_recording, verbose=1, tensorboard_log=f\"runs/{run.id}\")\n",
        "model.learn(\n",
        "    total_timesteps=config[\"total_timesteps\"],\n",
        "    callback=WandbCallback(\n",
        "        gradient_save_freq=10,\n",
        "        model_save_path=f\"models/{run.id}\",\n",
        "        verbose=2,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_SuperMario_25k')\n",
        "model.save(PPO_path)\n",
        "\n",
        "# Finish WandB run\n",
        "run.finish()\n",
        "\n",
        "# Evaluate the trained model\n",
        "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_Yu77_wt06A",
        "outputId": "55228dc4-0533-44a1-b278-b744c4757821"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.1)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra])\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra])\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.64.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3[extra])\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 29, in <module>\n",
            "    from pip._internal.utils.misc import ensure_dir\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 43, in <module>\n",
            "    from pip._internal.exceptions import CommandError, ExternallyManagedEnvironment\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/exceptions.py\", line 18, in <module>\n",
            "    from pip._vendor.requests.models import Request, Response\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/requests/__init__.py\", line 45, in <module>\n",
            "    from .exceptions import RequestsDependencyWarning\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/requests/exceptions.py\", line 9, in <module>\n",
            "    from .compat import JSONDecodeError as CompatJSONDecodeError\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/requests/compat.py\", line 10, in <module>\n",
            "    from pip._vendor import chardet\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/chardet/__init__.py\", line 24, in <module>\n",
            "    from .universaldetector import UniversalDetector\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/chardet/universaldetector.py\", line 52, in <module>\n",
            "    from .sbcsgroupprober import SBCSGroupProber\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/chardet/sbcsgroupprober.py\", line 45, in <module>\n",
            "    from .langthaimodel import TIS_620_THAI_MODEL\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 975, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting box2d-py\n",
            "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting gym_super_mario_bros==7.3.0\n",
            "  Downloading gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nes_py\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes_py) (1.25.2)\n",
            "Collecting pyglet<=1.5.21,>=1.4.0 (from nes_py)\n",
            "  Downloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (0.0.8)\n",
            "Building wheels for collected packages: nes_py\n",
            "  Building wheel for nes_py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes_py: filename=nes_py-8.2.1-cp310-cp310-linux_x86_64.whl size=535720 sha256=20876fce5cb3c130bc4af7ab7b527618edfe82d1b9d40ad14840d35e4cc214c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/a7/d5/9aa14b15df740a53d41f702e4c795731b6c4da7925deb8476c\n",
            "Successfully built nes_py\n",
            "Installing collected packages: pyglet, nes_py, gym_super_mario_bros\n",
            "Successfully installed gym_super_mario_bros-7.3.0 nes_py-8.2.1 pyglet-1.5.21\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 9b BipedalWalker-v3_EXP_9B ###"
      ],
      "metadata": {
        "id": "Mmp04xDPuT6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install 'stable-baselines3[extra]'\n",
        "!pip install wandb\n",
        "!pip install box2d-py\n",
        "!pip install gym_super_mario_bros==7.3.0 nes_py\n",
        "!pip install opencv-python\n",
        "\n",
        "import gym\n",
        "import os\n",
        "import wandb\n",
        "import gym_super_mario_bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from gym.wrappers import GrayScaleObservation\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv,VecVideoRecorder, VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "import gym\n",
        "\n",
        "# Define the environment name\n",
        "\n",
        "env_name = \"BipedalWalker-v3\"\n",
        "config = {\n",
        "    \"policy_type\": \"MlpPolicy\",\n",
        "    \"total_timesteps\": 250000,\n",
        "    \"env_name\": env_name,\n",
        "}\n",
        "run = wandb.init(\n",
        "    project=\"intro_to_gym\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,\n",
        "    monitor_gym=True,\n",
        "    save_code=True,\n",
        ")\n",
        "\n",
        "\n",
        "model = PPO(config[\"policy_type\"], env, verbose=1, tensorboard_log=f\"runs/{run.id}\")\n",
        "model.learn(\n",
        "    total_timesteps=config[\"total_timesteps\"],\n",
        "    callback=WandbCallback(\n",
        "        gradient_save_freq=100,\n",
        "        model_save_path=f\"models/{run.id}\",\n",
        "        verbose=2,\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_BipedalWalker_250k')\n",
        "model.save(PPO_path)\n",
        "\n",
        "\n",
        "evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
        "run.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9sRHi0WuA6x",
        "outputId": "9310da2d-f27e-4348-f3f3-4e392dd99ed4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Using cached stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[extra])\n",
            "  Using cached gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.1)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra])\n",
            "  Using cached Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n",
            "  Using cached AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
            "  Using cached AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra])\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra])\n",
            "  Using cached ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.64.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=2255d709381a4adb48524c6e00ce8cce5a3fe65492d05c8c9c48d2539beed957\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: farama-notifications, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, ale-py, shimmy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, AutoROM.accept-rom-license, autorom, nvidia-cusolver-cu12, stable-baselines3\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 farama-notifications-0.0.4 gymnasium-0.29.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 shimmy-1.3.0 stable-baselines3-2.3.2\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.3.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.0\n",
            "Collecting box2d-py\n",
            "  Using cached box2d-py-2.3.8.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: gym_super_mario_bros==7.3.0 in /usr/local/lib/python3.10/dist-packages (7.3.0)\n",
            "Requirement already satisfied: nes_py in /usr/local/lib/python3.10/dist-packages (8.2.1)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes_py) (1.25.2)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nes_py) (1.5.21)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (0.0.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 9c CartPole ###"
      ],
      "metadata": {
        "id": "jPw40Cvsuw7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the CartPole-v1 environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "env.seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, state_bins, action_size):\n",
        "        self.state_bins = state_bins\n",
        "        self.action_size = action_size\n",
        "        self.q_table = np.zeros(tuple(len(bins) + 1 for bins in state_bins) + (action_size,))\n",
        "        self.learning_rate = 0.1\n",
        "        self.discount_factor = 0.99\n",
        "        self.exploration_rate = 1.0\n",
        "        self.exploration_decay = 0.995\n",
        "        self.exploration_min = 0.01\n",
        "\n",
        "    def get_discrete_state(self, state):\n",
        "        discrete_state = []\n",
        "        for i in range(len(state)):\n",
        "            discrete_state.append(np.digitize(state[i], self.state_bins[i]) - 1)\n",
        "        return tuple(discrete_state)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.exploration_rate:\n",
        "            return random.choice(range(self.action_size))\n",
        "        return np.argmax(self.q_table[state])\n",
        "\n",
        "    def learn(self, state, action, reward, next_state, done):\n",
        "        best_next_action = np.argmax(self.q_table[next_state])\n",
        "        td_target = reward + self.discount_factor * self.q_table[next_state][best_next_action] * (not done)\n",
        "        td_error = td_target - self.q_table[state][action]\n",
        "        self.q_table[state][action] += self.learning_rate * td_error\n",
        "        if done:\n",
        "            self.exploration_rate = max(self.exploration_min, self.exploration_rate * self.exploration_decay)\n",
        "\n",
        "state_bins = [\n",
        "    np.linspace(-2.4, 2.4, 10),  # Cart position\n",
        "    np.linspace(-3.0, 3.0, 10),  # Cart velocity\n",
        "    np.linspace(-0.5, 0.5, 10),  # Pole angle\n",
        "    np.linspace(-2.0, 2.0, 10)   # Pole velocity at tip\n",
        "]\n",
        "\n",
        "# Initialize the Q-learning agent\n",
        "agent = QLearningAgent(state_bins=state_bins, action_size=env.action_space.n)\n",
        "\n",
        "# Training parameters\n",
        "num_episodes = 1000\n",
        "max_steps = 200\n",
        "rewards = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    state = agent.get_discrete_state(state)\n",
        "    total_reward = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        action = agent.choose_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        next_state = agent.get_discrete_state(next_state)\n",
        "        agent.learn(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    rewards.append(total_reward)\n",
        "    if (episode + 1) % 100 == 0:\n",
        "        print(f\"Episode {episode + 1}: Total Reward: {total_reward}\")\n",
        "\n",
        "print(\"Training finished.\\n\")\n",
        "\n",
        "# Plot the results\n",
        "plt.plot(rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Q-learning Training Performance on CartPole-v1')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "DSPHogqsumBC",
        "outputId": "d5453a08-ff77-4630-e1a1-410d6972e7da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100: Total Reward: 40.0\n",
            "Episode 200: Total Reward: 50.0\n",
            "Episode 300: Total Reward: 33.0\n",
            "Episode 400: Total Reward: 61.0\n",
            "Episode 500: Total Reward: 83.0\n",
            "Episode 600: Total Reward: 48.0\n",
            "Episode 700: Total Reward: 87.0\n",
            "Episode 800: Total Reward: 61.0\n",
            "Episode 900: Total Reward: 82.0\n",
            "Episode 1000: Total Reward: 61.0\n",
            "Training finished.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "moj4s41Hu5Y6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 10a FussyLogic_for_WashingMachine ###"
      ],
      "metadata": {
        "id": "U7hFc3ZkvVxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-fuzzy\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "from skfuzzy import control as ctrl\n",
        "\n",
        "# Define input variables\n",
        "dirtiness = ctrl.Antecedent(np.arange(0, 11, 1), 'dirtiness')\n",
        "fabric_type = ctrl.Antecedent(np.arange(0, 11, 1), 'fabric_type')\n",
        "load_size = ctrl.Antecedent(np.arange(0, 11, 1), 'load_size')\n",
        "\n",
        "# Define output variable\n",
        "washing_time = ctrl.Consequent(np.arange(0, 61, 1), 'washing_time')\n",
        "\n",
        "# Define membership functions\n",
        "dirtiness['low'] = fuzz.trimf(dirtiness.universe, [0, 0, 5])\n",
        "dirtiness['medium'] = fuzz.trimf(dirtiness.universe, [0, 5, 10])\n",
        "dirtiness['high'] = fuzz.trimf(dirtiness.universe, [5, 10, 10])\n",
        "\n",
        "fabric_type['delicate'] = fuzz.trimf(fabric_type.universe, [0, 0, 5])\n",
        "fabric_type['normal'] = fuzz.trimf(fabric_type.universe, [0, 5, 10])\n",
        "fabric_type['tough'] = fuzz.trimf(fabric_type.universe, [5, 10, 10])\n",
        "\n",
        "load_size['small'] = fuzz.trimf(load_size.universe, [0, 0, 5])\n",
        "load_size['medium'] = fuzz.trimf(load_size.universe, [0, 5, 10])\n",
        "load_size['large'] = fuzz.trimf(load_size.universe, [5, 10, 10])\n",
        "\n",
        "washing_time['short'] = fuzz.trimf(washing_time.universe, [0, 0, 30])\n",
        "washing_time['medium'] = fuzz.trimf(washing_time.universe, [0, 30, 60])\n",
        "washing_time['long'] = fuzz.trimf(washing_time.universe, [30, 60, 60])\n",
        "\n",
        "# Define fuzzy rules\n",
        "rule1 = ctrl.Rule(dirtiness['low'] & fabric_type['delicate'], washing_time['short'])\n",
        "rule2 = ctrl.Rule(dirtiness['medium'] & fabric_type['normal'] & load_size['small'], washing_time['short'])\n",
        "rule3 = ctrl.Rule(dirtiness['medium'] & fabric_type['normal'] & load_size['medium'], washing_time['medium'])\n",
        "rule4 = ctrl.Rule(dirtiness['medium'] & fabric_type['normal'] & load_size['large'], washing_time['long'])\n",
        "rule5 = ctrl.Rule(dirtiness['high'] | fabric_type['tough'], washing_time['long'])\n",
        "\n",
        "# Create control system\n",
        "washing_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5])\n",
        "washing_sim = ctrl.ControlSystemSimulation(washing_ctrl)\n",
        "\n",
        "# Define inputs\n",
        "washing_sim.input['dirtiness'] = 7\n",
        "washing_sim.input['fabric_type'] = 8\n",
        "washing_sim.input['load_size'] = 6\n",
        "\n",
        "# Compute the washing time\n",
        "washing_sim.compute()\n",
        "print(\"Recommended washing time:\", washing_sim.output[\"washing_time\"], \"minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPriqkDpvYBA",
        "outputId": "79730ac9-0c09-4992-c1d3-b7364a8350e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit-fuzzy-0.4.2.tar.gz (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (3.3)\n",
            "Building wheels for collected packages: scikit-fuzzy\n",
            "  Building wheel for scikit-fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-fuzzy: filename=scikit_fuzzy-0.4.2-py3-none-any.whl size=894078 sha256=bf7a4ab793f06ee56e19592a4410361f76c9a9c71af2d4804bf3fea4c3e2ba40\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/86/1b/dfd97134a2c8313e519bcebd95d3fedc7be7944db022094bc8\n",
            "Successfully built scikit-fuzzy\n",
            "Installing collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.4.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skfuzzy/image/__init__.py:17: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if LooseVersion(np.__version__) > LooseVersion(\"1.8\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended washing time: 35.268292682926806 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 10b FussyLogic_for_AC ###"
      ],
      "metadata": {
        "id": "NYi3oH88v9Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-fuzzy\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "from skfuzzy import control as ctrl\n",
        "\n",
        "# Define input variables\n",
        "temperature = ctrl.Antecedent(np.arange(0, 101, 1), 'temperature')\n",
        "humidity = ctrl.Antecedent(np.arange(0, 101, 1), 'humidity')\n",
        "\n",
        "# Define output variable\n",
        "cooling_power = ctrl.Consequent(np.arange(0, 101, 1), 'cooling_power')\n",
        "\n",
        "# Define membership functions\n",
        "temperature['cold'] = fuzz.trimf(temperature.universe, [0, 0, 50])\n",
        "temperature['comfortable'] = fuzz.trimf(temperature.universe, [20, 50, 80])\n",
        "temperature['hot'] = fuzz.trimf(temperature.universe, [50, 100, 100])\n",
        "\n",
        "humidity['low'] = fuzz.trimf(humidity.universe, [0, 0, 50])\n",
        "humidity['comfortable'] = fuzz.trimf(humidity.universe, [20, 50, 80])\n",
        "humidity['high'] = fuzz.trimf(humidity.universe, [50, 100, 100])\n",
        "\n",
        "cooling_power['low'] = fuzz.trimf(cooling_power.universe, [0, 0, 50])\n",
        "cooling_power['medium'] = fuzz.trimf(cooling_power.universe, [0, 50, 100])\n",
        "cooling_power['high'] = fuzz.trimf(cooling_power.universe, [50, 100, 100])\n",
        "\n",
        "# Define fuzzy rules\n",
        "rule1 = ctrl.Rule(temperature['cold'] & humidity['low'], cooling_power['high'])\n",
        "rule2 = ctrl.Rule(temperature['cold'] & humidity['high'], cooling_power['medium'])\n",
        "rule3 = ctrl.Rule(temperature['comfortable'] & humidity['comfortable'], cooling_power['medium'])\n",
        "rule4 = ctrl.Rule(temperature['hot'] & humidity['high'], cooling_power['high'])\n",
        "rule5 = ctrl.Rule(temperature['hot'] & humidity['low'], cooling_power['low'])\n",
        "\n",
        "# Create control system\n",
        "ac_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5])\n",
        "ac_sim = ctrl.ControlSystemSimulation(ac_ctrl)\n",
        "\n",
        "# Define inputs\n",
        "ac_sim.input['temperature'] = 75\n",
        "ac_sim.input['humidity'] = 40\n",
        "\n",
        "# Compute the cooling power\n",
        "ac_sim.compute()\n",
        "\n",
        "# Print the result\n",
        "print(\"Cooling Power:\", ac_sim.output['cooling_power'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKdO-Qdvp2j",
        "outputId": "3db768fc-9f7d-4aba-b73e-a7537d98a168"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (3.3)\n",
            "Cooling Power: 45.78471421042893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 10c FussyLogic_for_Railway ###"
      ],
      "metadata": {
        "id": "mKy1hglwwO9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-fuzzy\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "from skfuzzy import control as ctrl\n",
        "\n",
        "# Define input variables\n",
        "distance_to_station = ctrl.Antecedent(np.arange(0, 101, 1), 'distance_to_station')\n",
        "speed_limit = ctrl.Antecedent(np.arange(0, 101, 1), 'speed_limit')\n",
        "\n",
        "# Define output variable\n",
        "train_speed = ctrl.Consequent(np.arange(0, 101, 1), 'train_speed')\n",
        "\n",
        "# Define membership functions\n",
        "distance_to_station['close'] = fuzz.trimf(distance_to_station.universe, [0, 0, 50])\n",
        "distance_to_station['medium'] = fuzz.trimf(distance_to_station.universe, [0, 50, 100])\n",
        "distance_to_station['far'] = fuzz.trimf(distance_to_station.universe, [50, 100, 100])\n",
        "\n",
        "speed_limit['slow'] = fuzz.trimf(speed_limit.universe, [0, 0, 50])\n",
        "speed_limit['medium'] = fuzz.trimf(speed_limit.universe, [0, 50, 100])\n",
        "speed_limit['fast'] = fuzz.trimf(speed_limit.universe, [50, 100, 100])\n",
        "\n",
        "train_speed['slow'] = fuzz.trimf(train_speed.universe, [0, 0, 50])\n",
        "train_speed['medium'] = fuzz.trimf(train_speed.universe, [0, 50, 100])\n",
        "train_speed['fast'] = fuzz.trimf(train_speed.universe, [50, 100, 100])\n",
        "\n",
        "# Define fuzzy rules\n",
        "rule1 = ctrl.Rule(distance_to_station['close'], train_speed['slow'])\n",
        "rule2 = ctrl.Rule(distance_to_station['medium'] & speed_limit['medium'], train_speed['medium'])\n",
        "rule3 = ctrl.Rule(distance_to_station['far'] | speed_limit['fast'], train_speed['fast'])\n",
        "\n",
        "# Create control system\n",
        "train_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])\n",
        "train_sim = ctrl.ControlSystemSimulation(train_ctrl)\n",
        "\n",
        "# Define inputs\n",
        "train_sim.input['distance_to_station'] = 30\n",
        "train_sim.input['speed_limit'] = 70\n",
        "\n",
        "# Compute the train speed\n",
        "train_sim.compute()\n",
        "\n",
        "# Print the result\n",
        "print(\"Recommended Train Speed:\", train_sim.output['train_speed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4yLFQc8wcxq",
        "outputId": "40baf9db-10f1-4ff3-cd6e-61a10069d42a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (3.3)\n",
            "Recommended Train Speed: 49.999999999999986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 10d Decision tree from scratch ###"
      ],
      "metadata": {
        "id": "l4_StN52wr3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        num_samples, num_features = X.shape\n",
        "        num_classes = len(np.unique(y))\n",
        "\n",
        "        # Stopping criteria\n",
        "        if (depth == self.max_depth) or (num_classes == 1):\n",
        "            return np.bincount(y).argmax()\n",
        "\n",
        "        # Find best split\n",
        "        best_split = self._find_best_split(X, y)\n",
        "\n",
        "        if best_split is None:\n",
        "            return np.bincount(y).argmax()\n",
        "\n",
        "        feature_idx, threshold = best_split\n",
        "        left_indices = X[:, feature_idx] <= threshold\n",
        "        right_indices = ~left_indices\n",
        "\n",
        "        # Recursively build tree\n",
        "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return (feature_idx, threshold, left_tree, right_tree)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_split = None\n",
        "        best_gini = float('inf')\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        for feature_idx in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = X[:, feature_idx] <= threshold\n",
        "                right_indices = ~left_indices\n",
        "\n",
        "                gini = self._calculate_gini_index(y[left_indices], y[right_indices])\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_split = (feature_idx, threshold)\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def _calculate_gini_index(self, left_labels, right_labels):\n",
        "        total_samples = len(left_labels) + len(right_labels)\n",
        "        p_left = len(left_labels) / total_samples\n",
        "        p_right = len(right_labels) / total_samples\n",
        "\n",
        "        gini_left = 1 - sum([(np.sum(left_labels == c) / len(left_labels)) ** 2 for c in np.unique(left_labels)])\n",
        "        gini_right = 1 - sum([(np.sum(right_labels == c) / len(right_labels)) ** 2 for c in np.unique(right_labels)])\n",
        "\n",
        "        gini_index = p_left * gini_left + p_right * gini_right\n",
        "        return gini_index\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.array([self._traverse_tree(x, self.tree) for x in X])\n",
        "        return predictions\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        if isinstance(node, np.int64):\n",
        "            return node\n",
        "\n",
        "        feature_idx, threshold, left_tree, right_tree = node\n",
        "        if x[feature_idx] <= threshold:\n",
        "            return self._traverse_tree(x, left_tree)\n",
        "        else:\n",
        "            return self._traverse_tree(x, right_tree)\n",
        "\n",
        "    def print_tree(self):\n",
        "        self._print_node(self.tree)\n",
        "\n",
        "    def _print_node(self, node, depth=0):\n",
        "        if isinstance(node, np.int64):\n",
        "            print(\"  \" * depth, \"Class:\", node)\n",
        "        else:\n",
        "            feature_idx, threshold, left_tree, right_tree = node\n",
        "            print(\"  \" * depth, f\"Feature {feature_idx} <= {threshold}\")\n",
        "            print(\"  \" * (depth + 1), \"Left:\")\n",
        "            self._print_node(left_tree, depth + 1)\n",
        "            print(\"  \" * (depth + 1), \"Right:\")\n",
        "            self._print_node(right_tree, depth + 1)\n",
        "\n",
        "# Example usage\n",
        "X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
        "y_train = np.array([0, 0, 1, 1])\n",
        "\n",
        "# Initialize and train the decision tree classifier\n",
        "clf = DecisionTreeClassifier(max_depth=2)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print decision tree structure\n",
        "print(\"Decision Tree Structure:\")\n",
        "clf.print_tree()\n",
        "\n",
        "# Predictions\n",
        "X_test = np.array([[2, 2], [3, 3]])\n",
        "predictions = clf.predict(X_test)\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LJ5sa4lw0sw",
        "outputId": "1aec08bf-32e2-4880-a6c6-4f3929549346"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Structure:\n",
            " Feature 0 <= 2\n",
            "   Left:\n",
            "   Class: 0\n",
            "   Right:\n",
            "   Class: 1\n",
            "Predictions: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jlxA4Dpnw7cQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}